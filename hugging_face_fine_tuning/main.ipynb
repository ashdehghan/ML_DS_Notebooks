{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f346d655-ee6d-44e5-a33e-5918fefa5df5",
   "metadata": {},
   "source": [
    "# Fine-Tuning a Pre-Trained LLM\n",
    "\n",
    "In this note, I will go through a fine-tunning process of a pre-trained LLM. Note, this reference note, taken and learned from this reference:\n",
    "* [Hugging Face: Fine-Tune a Pretrained Model](https://huggingface.co/docs/transformers/training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c187a402-1a52-4d15-8e70-0a5abd8d7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8cf313-fd7b-4a1f-bbd5-0b6b1a478f0a",
   "metadata": {},
   "source": [
    "For now, let's just load some data from the `dataset` class. Let's take a look at the **Yelp Review** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e7b931-7702-4cb7-ac44-7e303347da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e27c90-2e91-479c-a109-a044108338cb",
   "metadata": {},
   "source": [
    "The dataset is a `dict`, containing training and test data. Each sub-dataset (train and test) is alsoa  `dict` with list `features` and `labels`, here features are the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7710f70-4f71-4d7c-85d2-4a5477e587c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "{'label': 4, 'text': \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2c51c9-bb47-4bb2-abc0-aae12c2ccece",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ffde0-fce2-4cf3-98e3-bc071d58c2a5",
   "metadata": {},
   "source": [
    "We can define a `map` function, that can be applied to elements of the `tarin` and `test` data, performing the tokenization. Note that we are loading a model specific tokenizer. The tokenizer has to be the same used by the model in the pre-training phase. We pass to the tokenizer 3 things:\n",
    "* The `text` component of each example, here an example if one item from the train or test list.\n",
    "* `padding`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55ebfea-93dc-4c01-befc-27281cb5a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db7ef4-9c7b-49a6-a3ae-56a466f6ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
